"""LLM Runner for local inference (llama.cpp, transformers, or other backends)."""

from .llm_interface import LLMRunner

__all__ = ["LLMRunner"]
