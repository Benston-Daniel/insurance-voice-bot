<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>InsuranceAI Assistant</title>
    <!-- Using Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom font */
        html, body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
        }

        /* Custom animation for the listening "sonar" effect */
        @keyframes pulse-ring {
            0% {
                transform: scale(0.33);
                opacity: 0.8;
            }
            80%, 100% {
                transform: scale(1.5);
                opacity: 0;
            }
        }
        .pulse-ring {
            /* Using the new brand color */
            background-color: #4f46e5; /* indigo-600 */
            animation: pulse-ring 2.5s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
        }
        .pulse-ring-delay-1 {
            background-color: #6366f1; /* indigo-500 */
            animation-delay: 0.8s;
        }
        .pulse-ring-delay-2 {
            background-color: #818cf8; /* indigo-400 */
            animation-delay: 1.6s;
        }
    </style>
</head>
<body class="bg-slate-100 flex flex-col h-screen">

    <!-- Header -->
    <header class="bg-white shadow-md p-4 flex items-center justify-between z-10">
        <div class="flex items-center space-x-3">
            <!-- Shield Icon for Insurance -->
            <svg class="h-8 w-8 text-indigo-600" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" d="M9 12.75L11.25 15 15 9.75m-3-7.036A11.959 11.959 0 013.598 6 11.99 11.99 0 003 9.749c0 5.592 3.824 10.29 9 11.623 5.176-1.333 9-6.03 9-11.623 0-1.314-.213-2.622-.602-3.852A11.959 11.959 0 0115 2.714v.001M9 12.75L11.25 15 15 9.75" />
            </svg>
            <h1 class="text-xl font-bold text-gray-800">InsuranceAI Assistant</h1>
        </div>
        <div class="flex items-center space-x-2">
            <span id="status-text" class="text-sm text-gray-500">Connecting...</span>
            <div id="status-dot" class="w-3 h-3 bg-gray-400 rounded-full transition-colors animate-pulse"></div>
        </div>
    </header>

    <!-- Chat Message List -->
    <main id="message-list" class="flex-1 overflow-y-auto p-6 space-y-4">
        <!-- Messages will be added here dynamically -->
    </main>

    <!-- Input Area Footer -->
    <footer id="input-area" class="bg-white p-4 shadow-inner flex items-center space-x-3">
        
        <!-- Text Input -->
        <input type="text" id="text-input" class="flex-1 bg-slate-100 border-transparent border-2 focus:border-indigo-500 p-3 rounded-lg focus:outline-none focus:ring-0 text-gray-900" placeholder="Ask about your policy...">
        
        <!-- Send Button (for text) -->
        <button id="send-button" class="bg-indigo-600 hover:bg-indigo-700 text-white p-3 rounded-lg transition-colors focus:outline-none focus:ring-2 focus:ring-indigo-500 shadow">
            <!-- Send Icon SVG -->
            <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 19l9 2-9-18-9 18 9-2zm0 0v-8" />
            </svg>
        </button>
        
        <!-- Mic Button (for voice) -->
        <button id="mic-button" class="bg-indigo-600 hover:bg-indigo-700 text-white p-3 rounded-full transition-colors focus:outline-none focus:ring-2 focus:ring-indigo-500 shadow disabled:opacity-50 disabled:bg-gray-600">
            <!-- Mic Icon SVG -->
            <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" viewBox="0 0 20 20" fill="currentColor">
                <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm_a1 1 0 00-2 0v4a5 5 0 0010 0V4a1 1 0 10-2 0v4a3 3 0 11-6 0V4zm-3 8a1 1 0 000 2h10a1 1 0 100-2H5z" clip-rule="evenodd" />
            </svg>
        </button>
    </footer>

    <!-- Recording Overlay (The "Huge Animation") -->
    <div id="recording-overlay" class="fixed inset-0 bg-gray-900 bg-opacity-90 flex flex-col items-center justify-center z-50 hidden transition-opacity duration-300">
        
        <!-- The pulsing "sonar" animation -->
        <div class="relative w-64 h-64 flex items-center justify-center">
            <div class="absolute w-full h-full rounded-full pulse-ring"></div>
            <div class="absolute w-full h-full rounded-full pulse-ring pulse-ring-delay-1"></div>
            <div class="absolute w-full h-full rounded-full pulse-ring pulse-ring-delay-2"></div>
            <!-- Center Mic Icon -->
            <svg xmlns="http://www.w3.org/2000/svg" class="h-24 w-24 text-white z-10" viewBox="0 0 20 20" fill="currentColor">
                <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm_a1 1 0 00-2 0v4a5 5 0 0010 0V4a1 1 0 10-2 0v4a3 3 0 11-6 0V4zm-3 8a1 1 0 000 2h10a1 1 0 100-2H5z" clip-rule="evenodd" />
            </svg>
        </div>

        <p class="text-2xl font-semibold mt-12 mb-8 text-white">Listening...</p>
        
        <!-- Stop Button -->
        <button id="stop-button" class="bg-red-600 hover:bg-red-700 text-white font-bold py-4 px-8 rounded-lg transition duration-300 shadow-lg focus:outline-none focus:ring-2 focus:ring-red-500 focus:ring-opacity-50">
            Stop
        </button>
    </div>


    <script>
        // DOM Elements
        const micButton = document.getElementById('mic-button');
        const recordingOverlay = document.getElementById('recording-overlay');
        const stopButton = document.getElementById('stop-button');
        const messageList = document.getElementById('message-list');
        const statusText = document.getElementById('status-text');
        const statusDot = document.getElementById('status-dot');
        const textInput = document.getElementById('text-input');
        const sendButton = document.getElementById('send-button');

        // State variables
        let mediaRecorder = null;
        let mediaStream = null;
        let socket = null;
        let ttsVoice = null;
        const audioMimeType = 'audio/webm;codecs=opus';

        // --- Helper Functions ---

        /**
         * Adds a message bubble to the chat window
         * @param {string} text - The message text
         * @param {'user' | 'ai'} sender - Who sent the message
         */
        function addMessageBubble(text, sender = 'user') {
            if (!text || text.trim() === "") return;

            const messageContainer = document.createElement('div');
            messageContainer.className = `flex ${sender === 'user' ? 'justify-end' : 'justify-start'}`;
            
            const bubble = document.createElement('div');
            bubble.className = `text-base p-4 rounded-lg max-w-xs md:max-w-md shadow-md ${
                sender === 'user'
                ? 'bg-indigo-600 text-white rounded-br-none'
                : 'bg-white text-gray-800 rounded-bl-none border border-gray-200'
            }`;
            
            // Set text content
            bubble.textContent = text;
            
            messageContainer.appendChild(bubble);
            messageList.appendChild(messageContainer);
            
            // Auto-scroll to the latest message
            messageList.scrollTop = messageList.scrollHeight;
        }

    /**
     * Finds and stores the best Tamil voice available in the browser.
     * Must be called after `onvoiceschanged` event.
     */
    function loadVoices() {
        const voices = window.speechSynthesis.getVoices();

        // Find the best Tamil voice
        // 'ta-IN' is Tamil (India)
        ttsVoice = voices.find(voice => voice.lang === 'ta-IN' && voice.name.includes('Google'));

        // Fallback: any Tamil voice
        if (!ttsVoice) {
            ttsVoice = voices.find(voice => voice.lang === 'ta-IN');
        }

        // Fallback: any Tamil (Sri Lanka) voice
        if (!ttsVoice) {
            ttsVoice = voices.find(voice => voice.lang === 'ta-LK');
        }

        if (ttsVoice) {
            console.log("TTS Voice selected:", ttsVoice.name);
        } else {
            console.warn("No Tamil (ta-IN) TTS voice found. Playback may use default language.");
        }
    }

    /**
     * Speaks the given text using the browser's TTS.
     * @param {string} text - The text to speak.
     */
    function speak(text) {
        if (!window.speechSynthesis) {
            console.error("Browser does not support Speech Synthesis.");
            return;
        }

        // Stop any currently playing speech
        window.speechSynthesis.cancel();

        const utterance = new SpeechSynthesisUtterance(text);

        // If we found a Tamil voice, use it.
        if (ttsVoice) {
            utterance.voice = ttsVoice;
            utterance.lang = 'ta-IN';
        }

        utterance.rate = 1.0;
        utterance.pitch = 1.0;

        window.speechSynthesis.speak(utterance);
    }

        function updateStatus(text, isConnected) {
            statusText.textContent = text;
            statusDot.classList.remove('animate-pulse');
            if (isConnected) {
                statusDot.classList.remove('bg-gray-400', 'bg-red-500');
                statusDot.classList.add('bg-green-500');
                micButton.disabled = false;
                sendButton.disabled = false;
            } else {
                statusDot.classList.remove('bg-green-500');
                statusDot.classList.add('bg-red-500');
                micButton.disabled = true;
                sendButton.disabled = true;
            }
        }

        function setupWebSocket() {
            // Re-enable connecting-state visuals
            updateStatus('Connecting...', false);
            statusDot.classList.add('animate-pulse');

            const wsUrl = `ws://${window.location.hostname || 'localhost'}:8765`;
            
            socket = new WebSocket(wsUrl);

            socket.onopen = () => {
                console.log('WebSocket connected.');
                updateStatus('Connected', true);
            };

            socket.onmessage = (event) => {
                let msg;
                try {
                    // All messages from the server are now JSON
                    msg = JSON.parse(event.data);
                } catch (e) {
                    console.error("Received non-JSON message:", event.data);
                    return;
                }

                if (msg.type === 'user') {
                    // This is the transcription from our own voice
                    // The server sends it back to us so we can display it
                    addMessageBubble(msg.text, 'user');
                } else if (msg.type === 'ai') {
                    // This is the AI's response to either text or voice
                    addMessageBubble(msg.text, 'ai');
                    // If server requests speech, speak the response (prefers Tamil voice if available)
                    if (msg.speak === true) {
                        try { speak(msg.text); } catch (e) { console.warn('TTS speak failed', e); }
                    }
                }
            };

            socket.onclose = () => {
                console.log('WebSocket disconnected.');
                updateStatus('Offline', false);
                // Optional: Try to reconnect after a delay
                setTimeout(setupWebSocket, 3000); // Reconnect every 3 seconds
            };

            socket.onerror = (error) => {
                console.error('WebSocket Error:', error);
                updateStatus('Error', false);
                socket.close(); // This will trigger the onclose reconnect logic
            };
        }

        async function startRecording() {
            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                if (!MediaRecorder.isTypeSupported(audioMimeType)) {
                    alert('This browser does not support the required audio format.');
                    return;
                }
                
                mediaRecorder = new MediaRecorder(mediaStream, { mimeType: audioMimeType });

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0 && socket && socket.readyState === WebSocket.OPEN) {
                        socket.send(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    console.log("MediaRecorder stopped. Sending STOP signal.");
                    if (socket && socket.readyState === WebSocket.OPEN) {
                        socket.send("STOP");
                    }
                    if (mediaStream) {
                        mediaStream.getTracks().forEach(track => track.stop());
                        mediaStream = null;
                    }
                };
                
                mediaRecorder.start(1000); // Send chunks every 1 second

            } catch (err) {
                console.error('Error getting user media:', err);
                addMessageBubble('Error: Could not access microphone.', 'ai');
                resetUI();
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
            resetUI();
        }

        function resetUI() {
            recordingOverlay.classList.add('hidden');
            micButton.disabled = false;
        }

        /**
         * Handles sending of typed text messages
         */
        function handleSendText() {
            if (!socket || socket.readyState !== WebSocket.OPEN) {
                addMessageBubble("Not connected. Please wait or refresh.", "ai");
                return;
            }

            const text = textInput.value;
            if (text.trim() === "") return;
            
            // 1. Add the typed text as a user bubble *immediately*
            addMessageBubble(text, 'user');
            
            // 2. Send the raw text to the server for the AI to process
            socket.send(text);
            
            // 3. Clear the input
            textInput.value = "";
        }

        // --- Event Listeners ---

        // Voice Input
        micButton.addEventListener('click', () => {
            if (!socket || socket.readyState !== WebSocket.OPEN) {
                addMessageBubble("Still connecting, please wait a moment...", "ai");
                return;
            }
            micButton.disabled = true;
            recordingOverlay.classList.remove('hidden');
            startRecording();
        });

        stopButton.addEventListener('click', () => {
            stopRecording();
        });

        // Text Input
        sendButton.addEventListener('click', handleSendText);
        textInput.addEventListener('keydown', (e) => {
            if (e.key === 'Enter') {
                e.preventDefault(); // Prevent new line
                handleSendText();
            }
        });

        // Add a welcome message and connect on load
        window.onload = () => {
            addMessageBubble("Hello! I'm your AI policy assistant. You can ask me questions about your coverage by typing or using the microphone.", "ai");
            setupWebSocket(); // Connect on page load
            // Load TTS voices
            if ('onvoiceschanged' in window.speechSynthesis) {
                window.speechSynthesis.onvoiceschanged = loadVoices;
            } else {
                // Fallback for browsers that don't fire the event
                loadVoices();
            }
        };

    </script>
</body>
</html>