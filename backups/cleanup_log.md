# Cleanup Log: Rasa â†’ Lightweight NLU+LLM Migration

## Date: November 11, 2025

### Summary
Successfully removed all Rasa artifacts and scaffolded a new lightweight, local LLM-based NLU + agent architecture for the Insurance Voice Bot (bilingual Tamil+English).

---

## âŒ Deleted Items

### 1. **Rasa Project** (`rasa_project/`)
   - **Contents removed:**
     - `data/nlu.yml` â€” NLU intents
     - `data/stories.yml` â€” dialogue stories
     - `domain.yml` â€” Rasa domain
     - `actions.py` â€” custom actions
     - `endpoints.yml` â€” action server endpoint config
   - **Reason:** Replaced with lightweight SentenceTransformers embeddings + local LLM runner
   - **Backup:** None (scaffold includes intent examples in `data/intents_bilingual.json`)

### 2. **Rasa Virtual Environment** (`rasa/`)
   - **Contents:** Python venv with Rasa SDK and dependencies
   - **Reason:** No longer needed; new venv created via `scripts/setup_venv.ps1` / `setup_venv.sh`
   - **Size freed:** ~500MB (estimated)

### 3. **Rasa Cache** (`.rasa/`)
   - **Contents:** Rasa model cache and temporary files
   - **Reason:** Stale cache; not applicable to new architecture
   - **Size freed:** ~100MB+ (estimated)

### 4. **Docker Compose Rasa Services** (in `docker-compose.yml`)
   - **Removed services:**
     - `rasa` (Rasa NLU server)
     - `action_server` (Rasa SDK actions)
   - **Updated:** Backend service now self-contained (no external dependencies)
   - **New environment vars:** `NLU_ENGINE`, `LLM_MODEL_NAME`

### 5. **Rasa Client Module** (in `backend/app/rasa_client.py`)
   - **Status:** Kept but deprecated (not used in new flow)
   - **Note:** Can be safely deleted in future refactoring

---

## âœ… Scaffolded Items

### 1. **NLU Engine** (`nlu_engine/`)
   - **Files:**
     - `__init__.py` â€” module init
     - `intent_classifier.py` â€” SentenceTransformers-based bilingual intent classifier
   - **Features:**
     - Multilingual embeddings (100+ languages, including Tamil)
     - Cosine similarity matching
     - Confidence thresholding
     - JSON-based intent configuration

### 2. **LLM Runner** (`llm_runner/`)
   - **Files:**
     - `__init__.py` â€” module init
     - `llm_interface.py` â€” abstract base + concrete runners
   - **Runners:**
     - `MockLLMRunner` â€” hardcoded responses (test mode)
     - `LlamaCppRunner` â€” CPU-optimized GGUF inference (llama.cpp)
     - `TransformersRunner` â€” HuggingFace transformers (CPU/GPU with bitsandbytes)

### 3. **Backend Updates** (`backend/app/`)
   - **New files:**
     - `orchestrator.py` â€” `InsuranceAgent` class (NLU + LLM + intent routing)
   - **Updated files:**
     - `main.py` â€” Rewired FastAPI endpoints to use new orchestrator
     - Endpoints: `/health`, `/query`, `/voice`
   - **Removed dependency:** `rasa_client.py` (deprecated)

### 4. **Data** (`data/`)
   - **Files:**
     - `intents_bilingual.json` â€” Intent examples (Tamil+English) with 7 sample intents
     - `mock_policies.json` â€” Mock insurance policy data (2 samples)
     - `mock_claims.json` â€” Mock claims data (2 samples)
   - **Features:** Bilingual support; easily extensible

### 5. **Scripts** (`scripts/`)
   - **Files:**
     - `setup_venv.ps1` â€” PowerShell venv setup (Windows)
     - `setup_venv.sh` â€” Bash venv setup (Linux/Mac)
   - **Features:**
     - Automatic venv creation
     - Interactive backend selection (SentenceTransformers, llama-cpp, transformers)
     - Dependency installation

### 6. **Models** (`models/README.md`)
   - **Content:**
     - Three runtime options with download instructions
     - Model recommendations (Mistral-7B, Llama-2-7B, etc.)
     - HuggingFace authentication steps
     - Bilingual support notes
     - File size reference table

### 7. **Documentation**
   - **Project README.md:** Comprehensive architecture, API docs, testing, development guide
   - **.gitignore:** Updated to exclude Rasa folders, models, venv, audio files, etc.
   - **docker-compose.yml:** Simplified to backend only

---

## ğŸ“Š Architecture Changes

### Before (Rasa-based)
```
Frontend â†’ FastAPI Backend â†’ Rasa Server (NLU) â†’ Rasa Action Server
                                      â†“
                           Intent Routing â†’ Policy/Claims Lookup
```

### After (Lightweight NLU+LLM)
```
Frontend â†’ FastAPI Backend â†’ SentenceTransformers (Intent) â†’ Intent Handler
                                      â†“
                              Policy/Claims Lookup OR LLM Fallback
```

**Benefits:**
- âŒ No external Rasa server needed
- âŒ No Docker dependency for NLU
- âœ… Embeddings-based NLU (fast, accurate)
- âœ… Local LLM support (CPU/GPU optional)
- âœ… Lightweight, edge-device friendly
- âœ… Easier to debug and customize

---

## ğŸ”„ Migration Checklist

- [x] Delete `rasa_project/`, `rasa/`, `.rasa/`
- [x] Remove Rasa services from docker-compose.yml
- [x] Create `nlu_engine/` module
- [x] Create `llm_runner/` module
- [x] Create `orchestrator.py` (insurance agent)
- [x] Update `main.py` (FastAPI endpoints)
- [x] Create bilingual intent examples (`data/intents_bilingual.json`)
- [x] Create setup scripts (`setup_venv.ps1`, `setup_venv.sh`)
- [x] Create models guide (`models/README.md`)
- [x] Update project README
- [x] Update docker-compose.yml
- [x] Update `.gitignore`
- [x] Create cleanup log (this file)

---

## ğŸš€ Next Steps for Users

1. **Setup venv:**
   ```powershell
   # Windows
   .\scripts\setup_venv.ps1
   ```
   ```bash
   # Linux/Mac
   chmod +x scripts/setup_venv.sh
   ./scripts/setup_venv.sh
   ```

2. **Choose LLM backend** (see `models/README.md`):
   - Mock (no download) â†’ fastest to test
   - llama-cpp (GGUF) â†’ CPU-friendly
   - Transformers â†’ GPU-accelerated (optional)

3. **Run backend:**
   ```bash
   export LLM_BACKEND=mock  # or llama-cpp, transformers
   python backend/app/main.py
   ```

4. **Test API:**
   ```bash
   curl -X POST http://localhost:8000/query \
     -H "Content-Type: application/json" \
     -d '{"message": "à®à®©à¯ à®ªà®¾à®²à®¿à®šà®¿ à®¨à®¿à®²à¯ˆ à®à®©à¯à®©?"}'
   ```

---

## ğŸ“ Notes

- **Backward Compatibility:** Rasa `.yml` files are NOT compatible with new architecture. Adapt intents to `data/intents_bilingual.json`.
- **Custom Intents:** Add new intents in `data/intents_bilingual.json` and corresponding handlers in `backend/app/orchestrator.py`.
- **Database Integration:** Replace mock policies/claims with real DB queries in `orchestrator.py`.
- **Model Updates:** To add LLM support, download a model and update `LLM_BACKEND` and `MODEL_PATH` environment variables.

---

## ğŸ“ Support

For issues or questions:
1. Check `models/README.md` for model-related setup
2. Review `backend/app/orchestrator.py` for architecture details
3. Test endpoints at `http://localhost:8000/docs` (Swagger UI)

---

**Status:** âœ… Migration Complete  
**Tested:** Basic syntax check passed  
**Ready for:** Development / Model Integration
